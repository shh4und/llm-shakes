{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas e dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub[pandas-datasets] gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "from time import sleep\n",
    "import gradio as gr\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "key = userdata.get('openAIkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"umerhaddii/shakespeare-plays-dialogues\",\n",
    "  \"hamlet.csv\",\n",
    ")\n",
    "\n",
    "macbeth_df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"umerhaddii/shakespeare-plays-dialogues\",\n",
    "  \"macbeth.csv\",\n",
    ")\n",
    "\n",
    "romeo_juliet_df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"umerhaddii/shakespeare-plays-dialogues\",\n",
    "  \"romeo_juliet.csv\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_juliet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para agrupar por cena e formatar corretamente\n",
    "def format_scene(df_scene):\n",
    "    \"\"\"Formata uma cena inteira mantendo personagens e direções de palco\"\"\"\n",
    "    formatted_scene = []\n",
    "\n",
    "    for _, row in df_scene.iterrows():\n",
    "        character = row['character']\n",
    "        dialogue = row['dialogue']\n",
    "\n",
    "        if character == \"[stage direction]\":\n",
    "            # Formatar direções de palco em itálico\n",
    "            formatted_scene.append(f\"[{dialogue}]\")\n",
    "        else:\n",
    "            # Formatar fala de personagem\n",
    "            formatted_scene.append(f\"{character}: {dialogue}\")\n",
    "\n",
    "    return \"\\n\".join(formatted_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extrair monólogos (falas longas de um personagem)\n",
    "def extract_monologues(df, min_lines=5):\n",
    "    \"\"\"Encontra monólogos (falas consecutivas de um mesmo personagem)\"\"\"\n",
    "    monologues = []\n",
    "    current_character = None\n",
    "    current_monologue = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        character = row['character']\n",
    "        dialogue = row['dialogue']\n",
    "\n",
    "        # Pular direções de palco\n",
    "        if character == \"[stage direction]\":\n",
    "            continue\n",
    "\n",
    "        # Se mudar de personagem, verificar se temos um monólogo\n",
    "        if character != current_character:\n",
    "            if current_character and len(current_monologue) >= min_lines:\n",
    "                monologues.append({\n",
    "                    \"character\": current_character,\n",
    "                    \"text\": \"\\n\".join(current_monologue)\n",
    "                })\n",
    "            current_character = character\n",
    "            current_monologue = [dialogue]\n",
    "        else:\n",
    "            current_monologue.append(dialogue)\n",
    "\n",
    "    # Verificar o último monólogo\n",
    "    if current_character and len(current_monologue) >= min_lines:\n",
    "        monologues.append({\n",
    "            \"character\": current_character,\n",
    "            \"text\": \"\\n\".join(current_monologue)\n",
    "        })\n",
    "\n",
    "    return monologues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar exemplos de fine-tuning para cenas completas\n",
    "def create_scene_examples(df):\n",
    "    examples = []\n",
    "\n",
    "    # Agrupar por ato e cena\n",
    "    grouped = df.groupby(['act', 'scene'])\n",
    "\n",
    "    for (act, scene), group in grouped:\n",
    "        formatted_scene = format_scene(group)\n",
    "\n",
    "        # Criar um tema baseado no conteúdo da cena\n",
    "        if \"murder\" in formatted_scene.lower() or \"kill\" in formatted_scene.lower():\n",
    "            tema = \"assassinato e vingança\"\n",
    "        elif \"love\" in formatted_scene.lower():\n",
    "            tema = \"amor proibido\"\n",
    "        elif \"ghost\" in formatted_scene.lower():\n",
    "            tema = \"encontro com um fantasma\"\n",
    "        elif \"witch\" in formatted_scene.lower():\n",
    "            tema = \"bruxaria e premonição\"\n",
    "        else:\n",
    "            tema = \"conflito entre personagens nobres\"\n",
    "\n",
    "        # Criar exemplo no formato JSONL\n",
    "        example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Você é William Shakespeare, o dramaturgo. Escreva no estilo autêntico de suas peças, usando linguagem arcaica, riqueza vocabular, estruturas dramáticas precisas (pentâmetro iâmbico, verso livre) e indicações de palco, metáforas, trocadilhos.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Escreva uma cena shakespeariana sobre {tema}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": formatted_scene}\n",
    "            ]\n",
    "        }\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar exemplos de fine-tuning para monólogos\n",
    "def create_monologue_examples(df):\n",
    "    examples = []\n",
    "    monologues = extract_monologues(df)\n",
    "\n",
    "    for mono in monologues:\n",
    "        character = mono[\"character\"]\n",
    "        text = mono[\"text\"]\n",
    "\n",
    "        # Criar tema com base no conteúdo do monólogo\n",
    "        if \"be or not to be\" in text.lower():\n",
    "            tema = \"contemplação da morte\"\n",
    "        elif \"wherefore art thou\" in text.lower():\n",
    "            tema = \"amor impossível\"\n",
    "        elif \"dagger\" in text.lower():\n",
    "            tema = \"culpa e alucinação\"\n",
    "        else:\n",
    "            # Temas genéricos para outros monólogos\n",
    "            temas = [\"reflexão filosófica\", \"dilema moral\", \"lamento pessoal\",\n",
    "                    \"ambição desmedida\", \"desespero humano\", \"confronto com o destino\"]\n",
    "            tema = random.choice(temas)\n",
    "\n",
    "        example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Você é William Shakespeare. Escreva monólogos dramáticos no seu estilo característico, usando pentâmetro iâmbico e linguagem arcaica rica em metáforas.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Escreva um monólogo shakespeariano para um personagem contemplando {tema}.\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"{character}:\\n{text}\"}\n",
    "            ]\n",
    "        }\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar exemplos de todas as peças\n",
    "all_examples = []\n",
    "\n",
    "# Cenas\n",
    "all_examples.extend(create_scene_examples(hamlet_df))\n",
    "all_examples.extend(create_scene_examples(macbeth_df))\n",
    "all_examples.extend(create_scene_examples(romeo_juliet_df))\n",
    "\n",
    "# Monólogos\n",
    "all_examples.extend(create_monologue_examples(hamlet_df))\n",
    "all_examples.extend(create_monologue_examples(macbeth_df))\n",
    "all_examples.extend(create_monologue_examples(romeo_juliet_df))\n",
    "\n",
    "# Limitar exemplos se necessário\n",
    "if len(all_examples) > 100:\n",
    "    all_examples = random.sample(all_examples, 100)\n",
    "\n",
    "# Salvar no formato JSONL\n",
    "with open(\"shakespeare_plays_finetuning.jsonl\", \"w\") as f:\n",
    "    for example in all_examples:\n",
    "        f.write(json.dumps(example) + \"\\n\")\n",
    "\n",
    "print(f\"Criados {len(all_examples)} exemplos para fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir 3 exemplos aleatórios para verificação\n",
    "\n",
    "sample_examples = random.sample(all_examples, 3)\n",
    "for i, example in enumerate(sample_examples):\n",
    "    print(f\"\\n--- Exemplo {i+1} ---\")\n",
    "    print(f\"Sistema: {example['messages'][0]['content']}\")\n",
    "    print(f\"Usuário: {example['messages'][1]['content']}\")\n",
    "    print(f\"Assistente (primeiras 100 chars): {example['messages'][2]['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_job(job_id):\n",
    "    \"\"\"Monitor fine-tuning job progress\"\"\"\n",
    "    while True:\n",
    "        job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        print(f\"Status: {job.status}\")\n",
    "\n",
    "        if job.status in [\"succeeded\", \"failed\"]:\n",
    "            return job\n",
    "\n",
    "        # List latest events\n",
    "        events = client.fine_tuning.jobs.list_events(\n",
    "            fine_tuning_job_id=job_id,\n",
    "            limit=5\n",
    "        )\n",
    "        for event in events.data:\n",
    "            print(f\"Event: {event.message}\")\n",
    "\n",
    "        sleep(20)  # Check every 20 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload do arquivo JSONL\n",
    "with open(\"/content/shakespeare_plays_finetuning.jsonl\", \"rb\") as file:\n",
    "    response = client.files.create(\n",
    "        file=file,\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "    file_id = response.id\n",
    "    print(f\"Arquivo carregado com ID: {file_id}\")\n",
    "\n",
    "# Criar o job de fine-tuning\n",
    "create_job = client.fine_tuning.jobs.create(\n",
    "    training_file=file_id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Custo-benefício melhor\n",
    "    method={\n",
    "        \"type\": \"supervised\",\n",
    "        \"supervised\": {\n",
    "            \"hyperparameters\": {\n",
    "                \"n_epochs\": 2,\n",
    "                \"learning_rate_multiplier\": 0.2,\n",
    "                \"batch_size\": 16\n",
    "            },\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "job_id = create_job.id\n",
    "print(f\"Fine-tuning iniciado! Job ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor the job until completion\n",
    "curr_job = monitor_job(job_id)\n",
    "if curr_job.status == \"succeeded\":\n",
    "    fine_tuned_model = curr_job.fine_tuned_model\n",
    "    print(f\"Fine-tuned model ID: {fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"Fine-tuning falhou.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criacao, Execucao da Aplicação e Testes dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models:\n",
    "\n",
    " - fine-tunados com 20 exemplos do dataset umerhaddii/shakespeare-plays-dialogues\n",
    "    1. ft:gpt-4o-mini-2024-07-18:hendrik::BJ8DAYRn  \n",
    "      - overfitting\n",
    "      - epochs: 3\n",
    "    2. ft:gpt-4o-mini-2024-07-18:hendrik::BJ95WQdI\n",
    "      - epochs: 1, learning_rate: 0.1\n",
    "    3. ft:gpt-4o-mini-2024-07-18:hendrik::BJa2oeL5\n",
    "      - epochs: 1, learning_rate: 0.1, batch_size = 8\n",
    "  \n",
    "  \n",
    "  - fine-tunados com 50 exemplos do dataset umerhaddii/shakespeare-plays-dialogues\n",
    "    4. ft:gpt-4o-mini-2024-07-18:hendrik::BJkjPlqi\n",
    "      - epochs: 1, learning_rate: 0.15, batch_size: 8\n",
    "  - fine-tunados com 100 exemplos do dataset umerhaddii/shakespeare-plays-dialogues\n",
    "    5. ft:gpt-4o-mini-2024-07-18:hendrik::BJkuBW58\n",
    "      - epochs: 2, learning_rate: 0.2, batch_size: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = \"ft:gpt-4o-mini-2024-07-18:hendrik::BJ8DAYRn\"\n",
    "model2 = \"ft:gpt-4o-mini-2024-07-18:hendrik::BJ95WQdI\"\n",
    "model3 = \"ft:gpt-4o-mini-2024-07-18:hendrik::BJa2oeL5\"\n",
    "model4 = \"ft:gpt-4o-mini-2024-07-18:hendrik::BJkjPlqi\"\n",
    "model5 = \"ft:gpt-4o-mini-2024-07-18:hendrik::BJkuBW58\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_texto_shakespeare(tema, tipo_texto=\"cena\", personagens=2, temperatura=0.8, model=\"gpt-4\"):\n",
    "    \"\"\"Usa o modelo fine-tuned para gerar texto shakespeariano\"\"\"\n",
    "    max_tks = 1500\n",
    "    # Adaptar prompt com base no tipo de texto\n",
    "    if tipo_texto == \"cena\":\n",
    "        content = f\"Crie uma cena original e nova (nova=que nao consta nas obras de shakespeare) no estilo autêntico de Shakespeare sobre '{tema}' com {personagens} personagens novos e originais. Incorpore linguagem e vocaulário: uso de arcaísmos, riqueza vocabular; estrutura métrica: pentâmetro iâmbico, verso livre; e figuras de linguagem e retórica: metáforas, trocadilhos.\"\n",
    "        max_tks = 2000\n",
    "    elif tipo_texto == \"monologo\":\n",
    "        content = f\"Crie um monólogo original e novo (novo=que nao consta nas obras de shakespeare) poderoso no estilo de Shakespeare sobre '{tema}'. Incorpore linguagem e vocaulário: uso de arcaísmos, riqueza vocabular; estrutura métrica: pentâmetro iâmbico, verso livre; e figuras de linguagem e retórica: metáforas, trocadilhos.\"\n",
    "        max_tks = 1200\n",
    "    else:\n",
    "        content = f\"Crie uma cena original e nova (nova=que nao consta nas obras de shakespeare) no estilo autêntico de Shakespeare sobre '{tema}' com {personagens} personagens novos e originais. Incorpore linguagem e vocaulário: uso de arcaísmos, riqueza vocabular; estrutura métrica: pentâmetro iâmbico, verso livre; e figuras de linguagem e retórica: metáforas, trocadilhos.\"\n",
    "\n",
    "    # Chamada à API com o modelo fine-tuned\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é William Shakespeare, o dramaturgo.\"},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ],\n",
    "        temperature = temperatura,\n",
    "        max_tokens=max_tks\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_estilo_shakespeare(texto_gerado):\n",
    "    \"\"\"Analisa o quão \"shakespeariano\" é o texto gerado\"\"\"\n",
    "\n",
    "    prompt_analise = f\"\"\"Analise o seguinte texto e avalie quanto ele se assemelha ao estilo autêntico de Shakespeare.\n",
    "\n",
    "    TEXTO:\n",
    "    {texto_gerado[:2500]}... (truncado)\n",
    "\n",
    "    Forneça uma análise detalhada considerando (escala de 1-10 para cade criterio):\n",
    "    1. Linguagem e vocabulário (uso de arcaísmos, riqueza vocabular)\n",
    "    2. Estrutura métrica (pentâmetro iâmbico, verso livre)\n",
    "    3. Figuras de linguagem e retórica (metáforas, trocadilhos)\n",
    "\n",
    "    4. Realize uma média dos criterios de autenticidade avaliados.\n",
    "\n",
    "    Realize uma análise sucinta, pórem precisa.\n",
    "    Destaque apenas os principais pontos.\n",
    "    Não leve em consideração a análise de temas e elementos sobre os quais Shakespeare nunca escreveu antes!\n",
    "    Se necessário, inclua exemplos específicos do texto que justifiquem sua avaliação.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um especialista em literatura shakespeariana.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_analise}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_imagem_shakespeare(texto, cena_titulo):\n",
    "    \"\"\"Gera uma imagem representando uma cena ou personagem da peça\"\"\"\n",
    "\n",
    "    # Extrair uma descrição concisa para a imagem\n",
    "    prompt_descricao = f\"\"\"\n",
    "    Com base neste texto de peça shakespeariana:\n",
    "    {texto[:1000]}...\n",
    "\n",
    "    Crie uma descrição visual concisa (máximo 50 palavras) para uma imagem dramática\n",
    "    representando a cena \"{cena_titulo}\". A descrição deve capturar a essência dramática da cena.\n",
    "    \"\"\"\n",
    "\n",
    "    descricao_response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um artista renascentista.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_descricao}\n",
    "        ],\n",
    "        temperature=0.8,\n",
    "        max_tokens=100\n",
    "    )\n",
    "\n",
    "    descricao_imagem = descricao_response.choices[0].message.content\n",
    "\n",
    "    # Gerar a imagem com DALL-E\n",
    "    imagem_response = client.images.generate(\n",
    "        prompt=f\"Uma ilustração dramática que represente bem o contexto: {descricao_imagem}\",\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "\n",
    "    return imagem_response.data[0].url, descricao_imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_aplicacao_shakespeare():\n",
    "    \"\"\"Cria a interface Gradio para o DeepFake Shakespeare\"\"\"\n",
    "\n",
    "    # Função que conecta todos os componentes\n",
    "    def processar_pedido(tema, tipo_texto, num_personagens):\n",
    "        # Gerar texto Shakespeare\n",
    "        texto_gerado = gerar_texto_shakespeare(tema, tipo_texto, num_personagens, model=model5) # Altere o modelo para o Gradio aqui\n",
    "        #print(texto_gerado)\n",
    "\n",
    "        # Analisar autenticidade\n",
    "        analise = analisar_estilo_shakespeare(texto_gerado)\n",
    "\n",
    "        # Gerar imagem\n",
    "        titulo_cena = f\"{tema} - {tipo_texto} shakespeariano\"\n",
    "        url_imagem, descricao_imagem = gerar_imagem_shakespeare(texto_gerado, titulo_cena)\n",
    "\n",
    "        return texto_gerado, analise, url_imagem, descricao_imagem\n",
    "\n",
    "    # Interface Gradio\n",
    "    with gr.Blocks(title=\"DeepFake Shakespeare: O Teatro que Nunca Existiu\") as app:\n",
    "        gr.Markdown(\"# 🎭 DeepFake Shakespeare: O Teatro que Nunca Existiu\")\n",
    "        gr.Markdown(\"Recrie peças shakespearianas que Shakespeare nunca escreveu, mas que poderiam ter existido!\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                tema_input = gr.Textbox(label=\"Tema da Peça\", placeholder=\"Ex: A Revolução Francesa, Napoleão, etc.\")\n",
    "                tipo_text = gr.Radio(\n",
    "                    [\"cena\", \"monologo\"],\n",
    "                    label=\"Tipo de Texto\",\n",
    "                    value=\"cena\"\n",
    "                )\n",
    "                num_personagens = gr.Slider(\n",
    "                    minimum=1,\n",
    "                    maximum=5,\n",
    "                    value=2,\n",
    "                    step=1,\n",
    "                    label=\"Número de Personagens\"\n",
    "                )\n",
    "                submit_btn = gr.Button(\"Gerar Obra Shakespeariana\")\n",
    "\n",
    "            with gr.Column():\n",
    "                img_output = gr.Image(label=\"Visualização da Cena\")\n",
    "                img_desc = gr.Textbox(label=\"Descrição da Imagem\")\n",
    "\n",
    "        with gr.Row():\n",
    "            texto_output = gr.Textbox(label=\"Texto Gerado\", lines=15)\n",
    "            analise_output = gr.Textbox(label=\"Análise de Autenticidade\", lines=15)\n",
    "\n",
    "        submit_btn.click(\n",
    "            processar_pedido,\n",
    "            inputs=[tema_input, tipo_text, num_personagens],\n",
    "            outputs=[texto_output, analise_output, img_output, img_desc]\n",
    "        )\n",
    "\n",
    "        gr.Markdown(\"## 📝 Sobre o Projeto\")\n",
    "        gr.Markdown(\"Este projeto explora o limite da originalidade da IA, recriando obras que Shakespeare nunca escreveu, mas que poderiam ter existido. Usa GPT-4o-mini com fine-tuning para gerar textos no estilo shakespeariano e DALL-E para visualizar as cenas.\")\n",
    "\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar a aplicação\n",
    "demo = criar_aplicacao_shakespeare()\n",
    "# share=True cria um lanca uma demo e cria um link publico, inline=True pra visualizar no colab/notebook\n",
    "demo.launch(share=True, inline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando e avaliando diferentes temperaturas e modelos para a geração de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_modelgpt4 = {}\n",
    "for temp in [0.8]:\n",
    "    resultados_modelgpt4[f\"temp_{temp}\"] = gerar_texto_shakespeare(\n",
    "        \"A Revolução Industrial\",\n",
    "        temperatura=temp,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in resultados_modelgpt4.items():\n",
    "#   print()\n",
    "#   print(k)\n",
    "#   print(v[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analises_modelgpt4 = {}\n",
    "for temp in [0.8]:\n",
    "    analises_modelgpt4[f\"temp_{temp}\"] = analisar_estilo_shakespeare(\n",
    "        resultados_modelgpt4[f\"temp_{temp}\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in analises_modelgpt4.items():\n",
    "  print()\n",
    "  print(k)\n",
    "  print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_model2 = {}\n",
    "for temp in [0.8]:\n",
    "    resultados_model2[f\"temp_{temp}\"] = gerar_texto_shakespeare(\n",
    "        \"A Revolução Industrial\",\n",
    "        temperatura=temp,\n",
    "        model=model2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in resultados_model2.items():\n",
    "#   print()\n",
    "#   print(k)\n",
    "#   print(v[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analises_model2 = {}\n",
    "for temp in [0.8]:\n",
    "    analises_model2[f\"temp_{temp}\"] = analisar_estilo_shakespeare(\n",
    "        resultados_model2[f\"temp_{temp}\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in analises_model2.items():\n",
    "  print()\n",
    "  print(k)\n",
    "  print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_model3 = {}\n",
    "for temp in [0.8]:\n",
    "    resultados_model3[f\"temp_{temp}\"] = gerar_texto_shakespeare(\n",
    "        \"A Revolução Industrial\",\n",
    "        temperatura=temp,\n",
    "        model=model3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in resultados_model3.items():\n",
    "#   print()\n",
    "#   print(k)\n",
    "#   print(v[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analises_model3 = {}\n",
    "for temp in [0.8]:\n",
    "    analises_model3[f\"temp_{temp}\"] = analisar_estilo_shakespeare(\n",
    "        resultados_model3[f\"temp_{temp}\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in analises_model3.items():\n",
    "  print()\n",
    "  print(k)\n",
    "  print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_model4 = {}\n",
    "for temp in [0.8]:\n",
    "    resultados_model4[f\"temp_{temp}\"] = gerar_texto_shakespeare(\n",
    "        \"A Revolução Industrial\",\n",
    "        temperatura=temp,\n",
    "        model=model4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in resultados_model4.items():\n",
    "#   print()\n",
    "#   print(k)\n",
    "#   print(v[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analises_model4 = {}\n",
    "for temp in [0.8]:\n",
    "    analises_model4[f\"temp_{temp}\"] = analisar_estilo_shakespeare(\n",
    "        resultados_model4[f\"temp_{temp}\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in analises_model4.items():\n",
    "  print()\n",
    "  print(k)\n",
    "  print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_model5 = {}\n",
    "for temp in [0.8]:\n",
    "    resultados_model5[f\"temp_{temp}\"] = gerar_texto_shakespeare(\n",
    "        \"A Revolução Industrial\",\n",
    "        temperatura=temp,\n",
    "        model=model5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in resultados_model5.items():\n",
    "#   print()\n",
    "#   print(k)\n",
    "#   print(v[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analises_model5 = {}\n",
    "for temp in [0.8]:\n",
    "    analises_model5[f\"temp_{temp}\"] = analisar_estilo_shakespeare(\n",
    "        resultados_model5[f\"temp_{temp}\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in analises_model5.items():\n",
    "  print()\n",
    "  print(k)\n",
    "  print(v)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SFEtXoJtykP6"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
